# ğŸ“ AI Educational - PDF to Embeddings Converter

## ğŸ“‹ Descriere
Sistem de conversie PDF Ã®n embeddings folosind modelul BAAI/bge-m3, care ruleazÄƒ local È™i pÄƒstreazÄƒ structura folderelor tale.

## ğŸ”§ Instalare È™i Setup

### Pas 1: PregÄƒtirea folderului
```bash
# CreeazÄƒ un folder nou pentru proiect
mkdir PDF_to_Embeddings
cd PDF_to_Embeddings
```

### Pas 2: Instalarea dependenÈ›elor
```bash
# InstaleazÄƒ Python packages necesare
pip install -r requirements.txt
```

**NOTÄ‚**: Prima rulare va descÄƒrca modelul BAAI/bge-m3 (~2GB). AsigurÄƒ-te cÄƒ ai conexiune la internet.

### Pas 3: Structura proiectului
```
PDF_to_Embeddings/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pdf_converter_working.py
â”œâ”€â”€ test_pdf_working.py
â”œâ”€â”€ SETUP_GUIDE.md
â”œâ”€â”€ embeddings_db/          # Se creeazÄƒ automat - aici se salveazÄƒ embeddings-urile
â”œâ”€â”€ new_pdfs/              # Se creeazÄƒ automat - pune PDF-urile noi aici
â”œâ”€â”€ processed_pdfs/        # Se creeazÄƒ automat - PDF-urile procesate se mutÄƒ aici
â””â”€â”€ materiale_didactice/   # CopiazÄƒ aici folderul tÄƒu cu PDF-uri (opÈ›ional)
```

## Utilizare:
```bash
python test_pdf_working.py
```

Aceasta va deschide meniul interactiv cu opÈ›iunile:
1. **ProceseazÄƒ un director Ã®ntreg** - ProceseazÄƒ toate PDF-urile dintr-un folder
2. **ProceseazÄƒ un singur fiÈ™ier** - ProceseazÄƒ un PDF specific  
3. **ProceseazÄƒ materiale_didactice** - ProceseazÄƒ folderul tÄƒu de materiale
4. **ListeazÄƒ colecÈ›iile** - Vezi ce embeddings ai creat
5. **TesteazÄƒ cÄƒutarea** - CautÄƒ Ã®n embeddings-uri
6. **IeÈ™ire**

### OpÈ›iunea 2: Procesare automatÄƒ (Batch)
```bash
python batch_converter.py
```

Aceasta monitorizeazÄƒ folderul `new_pdfs/` È™i proceseazÄƒ automat orice PDF nou adÄƒugat.

### OpÈ›iunea 3: Import direct Ã®n cod
```python
from pdf_embeddings_converter import PDFEmbeddingsConverter

# IniÈ›ializeazÄƒ convertorul
converter = PDFEmbeddingsConverter()

# ProceseazÄƒ un director
converter.process_directory("./materiale_didactice")

# ProceseazÄƒ un fiÈ™ier
converter.process_single_file("./test.pdf")

# CautÄƒ Ã®n embeddings
results = converter.search_similar("ce este un cerc", top_k=5)
```

## ğŸ—ï¸ Cum funcÈ›ioneazÄƒ

### 1. Structura colecÈ›iilor
Sistemul creeazÄƒ automat colecÈ›ii bazate pe structura de foldere:
```
materiale_didactice/Scoala_Normala/clasa_2/Matematica/matematica.pdf
â†“
ColecÈ›ia: scoala_normala_clasa_2_matematica
```

### 2. Procesarea PDF-urilor
- Extrage text din fiecare PDF
- Ãmparte textul Ã®n bucÄƒÈ›i de ~1000 cuvinte cu overlap de 100
- GenereazÄƒ embeddings cu BAAI/bge-m3
- SalveazÄƒ Ã®n ChromaDB cu metadata

### 3. Evitarea duplicatelor
- CalculeazÄƒ hash MD5 pentru fiecare fiÈ™ier
- Èšine evidenÈ›a fiÈ™ierelor procesate Ã®n `processed_files.json`
- ReproceseazÄƒ doar fiÈ™ierele modificate

## ğŸ“ Organizarea fiÈ™ierelor

### Pentru materiale existente:
1. CopiazÄƒ folderul `materiale_didactice` Ã®n `PDF_to_Embeddings/`
2. RuleazÄƒ `python main.py` È™i alege opÈ›iunea 3
3. Sistemul va procesa toate PDF-urile pÄƒstrÃ¢nd structura

### Pentru PDF-uri noi:
1. Pune PDF-urile noi Ã®n folderul `new_pdfs/`
2. RuleazÄƒ `python batch_converter.py`
3. PDF-urile vor fi procesate È™i mutate Ã®n `processed_pdfs/`

## ğŸ” CÄƒutare Ã®n embeddings

```python
# Exemplu de cÄƒutare
converter = PDFEmbeddingsConverter()

# CautÄƒ Ã®n toate colecÈ›iile
results = converter.search_similar("ce este un cerc")

# CautÄƒ Ã®ntr-o colecÈ›ie specificÄƒ
results = converter.search_similar(
    "ce este un cerc", 
    collection_name="scoala_normala_clasa_2_matematica"
)
```

## ğŸ› ï¸ ConfigurÄƒri avansate

### Modificarea dimensiunii bucÄƒÈ›ilor
```python
# Ãn pdf_embeddings_converter.py, linia ~85
chunks = self.chunk_text(text, chunk_size=1500, overlap=150)
```

### Schimbarea modelului
```python
# Ãn __init__, linia ~25
self.model = SentenceTransformer('alt-model-name')
```

### Configurarea ChromaDB
```python
# Pentru deployment cloud, modificÄƒ Ã®n __init__:
self.client = chromadb.HttpClient(host="your-host", port=8000)
```

## ğŸ› Troubleshooting

### Erori comune:

**1. "No module named 'sentence_transformers'"**
```bash
pip install sentence-transformers
```

**2. "CUDA out of memory"**
```python
# Ãn __init__, forÈ›eazÄƒ CPU:
self.model = SentenceTransformer('BAAI/bge-m3', device='cpu')
```

**3. "Cannot read PDF"**
- VerificÄƒ dacÄƒ PDF-ul nu este corupt
- ÃncearcÄƒ sÄƒ deschizi PDF-ul manual
- Unele PDF-uri scanate nu conÈ›in text extractabil

**4. Procesare lentÄƒ**
- Prima rulare descarcÄƒ modelul (~2GB)
- Modelul BGE-M3 este optimizat pentru CPU
- Pentru GPU: `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`

### Verificarea statusului
```bash
# Vezi ce colecÈ›ii ai creat
python -c "from pdf_embeddings_converter import PDFEmbeddingsConverter; PDFEmbeddingsConverter().list_collections()"

# Vezi cÃ¢te fiÈ™iere ai procesat
cat embeddings_db/processed_files.json
```

## ğŸ”— Integrare cu proiectul principal

Pentru a integra embeddings-urile Ã®n proiectul tÄƒu "AI Educational":

### 1. Copierea bazei de date
```bash
# CopiazÄƒ folderul embeddings_db Ã®n proiectul principal
cp -r embeddings_db/ /path/to/AISchool/embeddings_db/
```

### 2. Cod pentru cÄƒutare Ã®n proiectul principal
```python
import chromadb
from sentence_transformers import SentenceTransformer

class AITeacherWithEmbeddings:
    def __init__(self):
        self.model = SentenceTransformer('BAAI/bge-m3')
        self.client = chromadb.PersistentClient(path="./embeddings_db")
    
    def get_context_for_query(self, user_question: str, grade: str, subject: str):
        """GÄƒseÈ™te context relevant pentru Ã®ntrebarea utilizatorului"""
        
        # ConstruieÈ™te numele colecÈ›iei bazat pe clasÄƒ È™i materie
        collection_name = f"scoala_normala_clasa_{grade}_{subject.lower()}"
        
        try:
            collection = self.client.get_collection(collection_name)
            
            # CautÄƒ Ã®n embeddings
            query_embedding = self.model.encode([user_question])
            results = collection.query(
                query_embeddings=query_embedding.tolist(),
                n_results=3
            )
            
            # ReturneazÄƒ contextul gÄƒsit
            if results['documents']:
                context = "\n\n".join(results['documents'][0])
                return context
            else:
                return "Nu am gÄƒsit informaÈ›ii relevante Ã®n materialele didactice."
                
        except Exception as e:
            return f"Eroare la cÄƒutarea Ã®n embeddings: {e}"
    
    def answer_with_context(self, user_question: str, grade: str, subject: str):
        """RÄƒspunde la Ã®ntrebare folosind contextul din embeddings"""
        context = self.get_context_for_query(user_question, grade, subject)
        
        # Aici integrezi cu LLM-ul tÄƒu (OpenAI, Claude, etc.)
        prompt = f"""
        EÈ™ti un profesor AI care ajutÄƒ copiii cu temele. 
        
        Context din materialele didactice:
        {context}
        
        Ãntrebarea elevului: {user_question}
        
        RÄƒspunde simplu È™i pedagogic, adaptÃ¢nd explicaÈ›ia pentru clasa {grade}.
        FoloseÈ™te doar informaÈ›iile din context È™i explicÄƒ pas cu pas.
        """
        
        # ReturneazÄƒ prompt-ul pentru LLM sau proceseazÄƒ direct
        return prompt
```

### 3. API pentru Railway deployment
```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI(title="AI Educational API")

class QuestionRequest(BaseModel):
    question: str
    grade: str
    subject: str
    school_type: str = "normala"  # sau "muzica"

teacher = AITeacherWithEmbeddings()

@app.post("/ask")
async def ask_teacher(request: QuestionRequest):
    try:
        context = teacher.get_context_for_query(
            request.question, 
            request.grade, 
            request.subject
        )
        
        return {
            "context": context,
            "success": True
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/collections")
async def list_collections():
    """Lista toate colecÈ›iile disponibile"""
    collections = teacher.client.list_collections()
    return {
        "collections": [
            {
                "name": col.name,
                "count": col.count()
            } for col in collections
        ]
    }
```

## ğŸ“Š Monitorizare È™i statistici

### Script pentru statistici
```python
# stats.py
from pdf_embeddings_converter import PDFEmbeddingsConverter
import json

def generate_stats():
    converter = PDFEmbeddingsConverter()
    collections = converter.client.list_collections()
    
    stats = {
        "total_collections": len(collections),
        "total_documents": sum(col.count() for col in collections),
        "collections_detail": []
    }
    
    for col in collections:
        stats["collections_detail"].append({
            "name": col.name,
            "document_count": col.count(),
            "metadata": col.metadata
        })
    
    # SalveazÄƒ statisticile
    with open("embeddings_stats.json", "w", encoding="utf-8") as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“Š Statistici generate:")
    print(f"   - {stats['total_collections']} colecÈ›ii")
    print(f"   - {stats['total_documents']} documente totale")
    
    return stats

if __name__ == "__main__":
    generate_stats()
```

## ğŸš€ Deploy pe Railway

### 1. PregÄƒtirea pentru production
```python
# config.py
import os

class Config:
    # Pentru development
    EMBEDDINGS_PATH = "./embeddings_db"
    MODEL_NAME = "BAAI/bge-m3"
    
    # Pentru production
    if os.getenv("RAILWAY_ENVIRONMENT"):
        EMBEDDINGS_PATH = "/app/embeddings_db"
        # FoloseÈ™te un model mai mic pentru production
        MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
```

### 2. Dockerfile pentru Railway
```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

# InstaleazÄƒ dependenÈ›ele de sistem
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# CopiazÄƒ requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# CopiazÄƒ codul aplicaÈ›iei
COPY . .

# CopiazÄƒ embeddings-urile (dacÄƒ nu sunt prea mari)
COPY embeddings_db ./embeddings_db

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 3. Alternative pentru embeddings mari
Pentru cÄƒ embeddings-urile pot fi mari pentru Railway:

**OpÈ›iunea A: S3/Cloud Storage**
```python
import boto3

class CloudEmbeddingsManager:
    def __init__(self):
        self.s3 = boto3.client('s3')
        self.bucket = "your-embeddings-bucket"
    
    def download_embeddings(self):
        # DescarcÄƒ embeddings-urile la startup
        local_path = "./embeddings_db"
        # ... cod pentru download din S3
```

**OpÈ›iunea B: Embeddings on-demand**
```python
class OnDemandEmbeddings:
    def __init__(self):
        self.model = SentenceTransformer('BAAI/bge-m3')
        self.pdf_cache = {}  # Cache pentru PDF-uri procesate
    
    def get_context(self, query, pdf_content):
        # GenereazÄƒ embeddings Ã®n timp real
        if pdf_content not in self.pdf_cache:
            chunks = self.chunk_text(pdf_content)
            embeddings = self.model.encode(chunks)
            self.pdf_cache[pdf_content] = (chunks, embeddings)
        
        chunks, embeddings = self.pdf_cache[pdf_content]
        # CautÄƒ cel mai relevant chunk
        query_embedding = self.model.encode([query])
        # ... logica de cÄƒutare
```

## ğŸ”§ Comenzi utile

```bash
# VerificÄƒ dimensiunea bazei de date
du -sh embeddings_db/

# È˜terge toate embeddings-urile (ATENÈšIE!)
rm -rf embeddings_db/

# ReproceseazÄƒ doar fiÈ™ierele modificate
rm embeddings_db/processed_files.json

# CreeazÄƒ backup
tar -czf embeddings_backup.tar.gz embeddings_db/

# RestaureazÄƒ backup
tar -xzf embeddings_backup.tar.gz
```

## ğŸ“ To-Do pentru integrare

1. âœ… **CreazÄƒ sistemul de embeddings local**
2. âœ… **TesteazÄƒ pe materialele tale didactice**
3. ğŸ”² **IntegreazÄƒ cu proiectul AI Educational**
4. ğŸ”² **OptimizeazÄƒ pentru Railway deployment**
5. ğŸ”² **ConecteazÄƒ cu Bubble.io frontend**
6. ğŸ”² **AdaugÄƒ cache pentru performanÈ›Äƒ**
7. ğŸ”² **ImplementeazÄƒ logging È™i monitoring**

## ğŸ“ Support

Pentru probleme sau Ã®ntrebÄƒri:
1. VerificÄƒ secÈ›iunea Troubleshooting
2. RuleazÄƒ `python -c "from pdf_embeddings_converter import PDFEmbeddingsConverter; PDFEmbeddingsConverter().list_collections()"`
3. VerificÄƒ log-urile Ã®n terminal
