"""
Script pentru testarea optimizÄƒrilor implementate
VerificÄƒ toate Ã®mbunÄƒtÄƒÈ›irile: BGE prefix, normalizare, chunking, etc.
"""

import time
import numpy as np
from pdf_converter_working import PDFEmbeddingsConverter, RETRIEVAL_INSTRUCTION
import os

def test_retrieval_instruction():
    """Test 1: VerificÄƒ dacÄƒ se foloseÈ™te instrucÈ›iunea de retrieval"""
    print("ğŸ§ª Test 1: InstrucÈ›iune de retrieval")
    print("-" * 40)
    
    converter = PDFEmbeddingsConverter()
    
    # Test cu È™i fÄƒrÄƒ instrucÈ›iune
    test_text = "Matematica este È™tiinÈ›a numerelor"
    
    # Cu instrucÈ›iune (cum ar trebui sÄƒ fie)
    start_time = time.time()
    embedding_with = converter.model.encode(
        [RETRIEVAL_INSTRUCTION + test_text], 
        normalize_embeddings=True
    )
    time_with = time.time() - start_time
    
    # FÄƒrÄƒ instrucÈ›iune (pentru comparaÈ›ie)
    start_time = time.time()
    embedding_without = converter.model.encode(
        [test_text], 
        normalize_embeddings=True
    )
    time_without = time.time() - start_time
    
    print(f"âœ… InstrucÈ›iune folositÄƒ: '{RETRIEVAL_INSTRUCTION.strip()}'")
    print(f"ğŸ“Š Embedding cu instrucÈ›iune: {embedding_with.shape}")
    print(f"ğŸ“Š Embedding fÄƒrÄƒ instrucÈ›iune: {embedding_without.shape}")
    print(f"â±ï¸ Timp cu instrucÈ›iune: {time_with:.3f}s")
    print(f"â±ï¸ Timp fÄƒrÄƒ instrucÈ›iune: {time_without:.3f}s")
    
    # VerificÄƒ dacÄƒ embeddings-urile sunt diferite
    similarity = np.dot(embedding_with[0], embedding_without[0])
    print(f"ğŸ” Similaritate Ã®ntre embeddings: {similarity:.4f}")
    print(f"âœ… Embeddings diferite: {'Da' if similarity < 0.99 else 'Nu'}")
    
    return True

def test_normalization():
    """Test 2: VerificÄƒ normalizarea embeddings-urilor"""
    print("\nğŸ§ª Test 2: Normalizarea embeddings-urilor")
    print("-" * 40)
    
    converter = PDFEmbeddingsConverter()
    
    test_texts = [
        "Text scurt pentru test",
        "Acesta este un text mai lung pentru a verifica dacÄƒ normalizarea funcÈ›ioneazÄƒ corect Ã®n toate cazurile"
    ]
    
    for i, text in enumerate(test_texts):
        embedding = converter.model.encode(
            [RETRIEVAL_INSTRUCTION + text], 
            normalize_embeddings=True
        )
        
        norm = np.linalg.norm(embedding[0])
        print(f"ğŸ“ Text {i+1}: {text[:30]}...")
        print(f"ğŸ“Š Norma vectorului: {norm:.6f}")
        print(f"âœ… Normalizat corect: {'Da' if abs(norm - 1.0) < 1e-5 else 'Nu'}")
    
    return True

def test_advanced_chunking():
    """Test 3: TesteazÄƒ chunking-ul avansat cu overlap"""
    print("\nğŸ§ª Test 3: Chunking avansat cu overlap")
    print("-" * 40)
    
    converter = PDFEmbeddingsConverter()
    
    # Text de test lung
    test_text = """
    Matematica este È™tiinÈ›a care studiazÄƒ numerele, structurile, spaÈ›iul È™i schimbarea. 
    Ea se bazeazÄƒ pe logicÄƒ È™i pe demonstraÈ›ii riguroase. Principalele ramuri ale matematicii sunt 
    algebra, geometria, analiza matematicÄƒ È™i teoria numerelor. Matematica este folositÄƒ Ã®n multe 
    domenii precum fizica, ingineeria, economia È™i informatica. ImportanÈ›a matematicii Ã®n educaÈ›ie 
    este recunoscutÄƒ la nivel mondial. Elevii Ã®nvaÈ›Äƒ matematica de la o vÃ¢rstÄƒ fragedÄƒ. 
    Conceptele matematice de bazÄƒ includ adunarea, scÄƒderea, Ã®nmulÈ›irea È™i Ã®mpÄƒrÈ›irea. 
    Geometria studiazÄƒ formele È™i spaÈ›iul. Algebra lucreazÄƒ cu simboluri È™i ecuaÈ›ii. 
    Analiza matematicÄƒ se ocupÄƒ cu limite È™i derivate. Statistica analizeazÄƒ datele È™i probabilitÄƒÈ›ile.
    """ * 3  # RepetÄƒ pentru a face textul mai lung
    
    # SimuleazÄƒ text_pages pentru test
    text_pages = [(test_text, 1)]
    
    # Test chunking cu parametri diferiÈ›i
    chunks_400, metadata_400 = converter.advanced_chunk_text(test_text, text_pages, chunk_size=400, overlap=80)
    chunks_200, metadata_200 = converter.advanced_chunk_text(test_text, text_pages, chunk_size=200, overlap=40)
    
    print(f"ğŸ“ Text original: {len(test_text.split())} cuvinte")
    print(f"ğŸ”§ Chunk size 400, overlap 80: {len(chunks_400)} chunks")
    print(f"ğŸ”§ Chunk size 200, overlap 40: {len(chunks_200)} chunks")
    
    # VerificÄƒ overlap-ul
    if len(chunks_400) > 1:
        chunk1_words = set(chunks_400[0].split())
        chunk2_words = set(chunks_400[1].split())
        overlap_words = len(chunk1_words & chunk2_words)
        print(f"ğŸ”— Overlap Ã®ntre primul È™i al doilea chunk: {overlap_words} cuvinte")
    
    # VerificÄƒ metadata paginilor
    if metadata_400:
        first_meta = metadata_400[0]
        print(f"ğŸ“„ Primul chunk: pagina {first_meta['page_from']}-{first_meta['page_to']}")
        print(f"ğŸ“Š Cuvinte Ã®n primul chunk: {first_meta['word_count']}")
        print(f"ğŸ“ PropoziÈ›ii Ã®n primul chunk: {first_meta['sentence_count']}")
    
    return True

def test_cosine_similarity():
    """Test 4: VerificÄƒ setarea metric cosine Ã®n ChromaDB"""
    print("\nğŸ§ª Test 4: MetricÄƒ cosine Ã®n ChromaDB")
    print("-" * 40)
    
    converter = PDFEmbeddingsConverter()
    
    # CreeazÄƒ o colecÈ›ie de test
    test_collection_name = "test_cosine_optimization"
    
    try:
        # È˜terge colecÈ›ia de test dacÄƒ existÄƒ
        try:
            converter.client.delete_collection(test_collection_name)
        except:
            pass
        
        # CreeazÄƒ colecÈ›ia cu metricÄƒ cosine
        collection = converter.client.get_or_create_collection(
            name=test_collection_name,
            metadata={
                "hnsw:space": "cosine",
                "test": True
            }
        )
        
        print(f"âœ… ColecÈ›ie de test creatÄƒ: {test_collection_name}")
        
        # VerificÄƒ metadata
        metadata = collection.metadata or {}
        hnsw_space = metadata.get("hnsw:space", "None")
        print(f"ğŸ¯ HNSW space configurat: {hnsw_space}")
        print(f"âœ… MetricÄƒ cosine setatÄƒ: {'Da' if hnsw_space == 'cosine' else 'Nu'}")
        
        # Test cu embeddings de test
        test_embeddings = [
            [0.1, 0.2, 0.3, 0.4],  # Vector normalizat 1
            [0.2, 0.3, 0.4, 0.1],  # Vector normalizat 2
        ]
        
        # NormalizeazÄƒ vectorii
        test_embeddings = [
            (np.array(vec) / np.linalg.norm(vec)).tolist() 
            for vec in test_embeddings
        ]
        
        collection.add(
            embeddings=test_embeddings,
            documents=["Document test 1", "Document test 2"],
            ids=["test1", "test2"]
        )
        
        # Test query
        query_embedding = [0.15, 0.25, 0.35, 0.25]
        query_embedding = (np.array(query_embedding) / np.linalg.norm(query_embedding)).tolist()
        
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=2
        )
        
        if results.get('distances'):
            distances = results['distances'][0]
            print(f"ğŸ“ DistanÈ›e cosine: {[f'{d:.4f}' for d in distances]}")
            print(f"âœ… DistanÈ›e Ã®n intervalul [0,2]: {'Da' if all(0 <= d <= 2 for d in distances) else 'Nu'}")
        
        # Cleanup
        converter.client.delete_collection(test_collection_name)
        print("ğŸ—‘ï¸ ColecÈ›ie de test È™tearsÄƒ")
        
    except Exception as e:
        print(f"âŒ Eroare test cosine: {e}")
        return False
    
    return True

def test_search_with_scores():
    """Test 5: VerificÄƒ cÄƒutarea cu scoruri È™i sortare globalÄƒ"""
    print("\nğŸ§ª Test 5: CÄƒutare cu scoruri È™i sortare globalÄƒ")
    print("-" * 40)
    
    converter = PDFEmbeddingsConverter()
    
    # CreeazÄƒ colecÈ›ii de test cu documente
    test_collections = ["test_search_1", "test_search_2"]
    
    try:
        for col_name in test_collections:
            # È˜terge dacÄƒ existÄƒ
            try:
                converter.client.delete_collection(col_name)
            except:
                pass
        
        # CreeazÄƒ colecÈ›ii cu documente de test
        docs_col1 = [
            "Matematica este È™tiinÈ›a numerelor È™i calculelor",
            "Geometria studiazÄƒ formele È™i spaÈ›iul",
        ]
        
        docs_col2 = [
            "Fizica este È™tiinÈ›a naturii È™i miÈ™cÄƒrii",
            "Chimia studiazÄƒ substanÈ›ele È™i reacÈ›iile",
        ]
        
        # AdaugÄƒ Ã®n prima colecÈ›ie
        col1 = converter.client.create_collection(
            "test_search_1",
            metadata={"hnsw:space": "cosine"}
        )
        
        embeddings1 = converter.model.encode(
            [RETRIEVAL_INSTRUCTION + doc for doc in docs_col1],
            normalize_embeddings=True
        )
        
        col1.add(
            embeddings=embeddings1.tolist(),
            documents=docs_col1,
            ids=[f"doc1_{i}" for i in range(len(docs_col1))]
        )
        
        # AdaugÄƒ Ã®n a doua colecÈ›ie
        col2 = converter.client.create_collection(
            "test_search_2", 
            metadata={"hnsw:space": "cosine"}
        )
        
        embeddings2 = converter.model.encode(
            [RETRIEVAL_INSTRUCTION + doc for doc in docs_col2],
            normalize_embeddings=True
        )
        
        col2.add(
            embeddings=embeddings2.tolist(),
            documents=docs_col2,
            ids=[f"doc2_{i}" for i in range(len(docs_col2))]
        )
        
        print(f"âœ… ColecÈ›ii de test create cu {len(docs_col1)} + {len(docs_col2)} documente")
        
        # Test cÄƒutare cu sortare globalÄƒ
        query = "È™tiinÈ›Äƒ"
        results = converter.search_similar(query, top_k=3)
        
        if results and results.get('documents') and results['documents'][0]:
            docs = results['documents'][0]
            similarities = results.get('similarities', [[]])[0] or []
            collections = results.get('collections', [[]])[0] or []
            
            print(f"ğŸ” Query: '{query}'")
            print(f"ğŸ“Š Rezultate gÄƒsite: {len(docs)}")
            
            for i, (doc, sim, col) in enumerate(zip(docs, similarities, collections)):
                print(f"  {i+1}. Similaritate: {sim:.4f} | ColecÈ›ie: {col}")
                print(f"     Text: {doc[:50]}...")
            
            # VerificÄƒ dacÄƒ sunt sortate descrescÄƒtor
            if len(similarities) > 1:
                is_sorted = all(similarities[i] >= similarities[i+1] for i in range(len(similarities)-1))
                print(f"âœ… Rezultate sortate global: {'Da' if is_sorted else 'Nu'}")
        
        # Cleanup
        for col_name in test_collections:
            try:
                converter.client.delete_collection(col_name)
            except:
                pass
        
        print("ğŸ—‘ï¸ ColecÈ›ii de test È™terse")
        
    except Exception as e:
        print(f"âŒ Eroare test cÄƒutare: {e}")
        return False
    
    return True

def test_performance_improvements():
    """Test 6: VerificÄƒ Ã®mbunÄƒtÄƒÈ›irile de performanÈ›Äƒ"""
    print("\nğŸ§ª Test 6: ÃmbunÄƒtÄƒÈ›iri de performanÈ›Äƒ")
    print("-" * 40)
    
    converter = PDFEmbeddingsConverter()
    
    # Test streaming embeddings vs batch
    test_chunks = [
        f"Chunk de test numÄƒrul {i} cu text suficient pentru a testa performanÈ›a sistemului optimizat"
        for i in range(20)
    ]
    
    print(f"ğŸ“ Testez {len(test_chunks)} chunks")
    
    # Test streaming (implementarea optimizatÄƒ)
    start_time = time.time()
    embeddings_streaming = converter.generate_embeddings_streaming(test_chunks)
    streaming_time = time.time() - start_time
    
    print(f"âš¡ Streaming embeddings: {embeddings_streaming.shape} Ã®n {streaming_time:.2f}s")
    print(f"ğŸ“Š Viteza: {len(test_chunks)/streaming_time:.2f} chunks/s")
    
    # VerificÄƒ cÄƒ embeddings-urile sunt normalizate
    if embeddings_streaming.size > 0:
        norms = np.linalg.norm(embeddings_streaming, axis=1)
        avg_norm = np.mean(norms)
        print(f"ğŸ“ Norma medie a embeddings-urilor: {avg_norm:.6f}")
        print(f"âœ… Embeddings normalizate: {'Da' if abs(avg_norm - 1.0) < 1e-4 else 'Nu'}")
    
    return True

def test_memory_usage():
    """Test 7: VerificÄƒ utilizarea memoriei"""
    print("\nğŸ§ª Test 7: Utilizarea memoriei")
    print("-" * 40)
    
    import psutil
    import gc
    
    process = psutil.Process()
    
    # Memorie Ã®nainte
    memory_before = process.memory_info().rss / 1024 / 1024  # MB
    
    converter = PDFEmbeddingsConverter()
    
    # Memorie dupÄƒ Ã®ncÄƒrcare
    memory_after = process.memory_info().rss / 1024 / 1024  # MB
    
    print(f"ğŸ’¾ Memorie Ã®nainte de Ã®ncÄƒrcare: {memory_before:.1f} MB")
    print(f"ğŸ’¾ Memorie dupÄƒ Ã®ncÄƒrcare model: {memory_after:.1f} MB")
    print(f"ğŸ“Š Memorie folositÄƒ de model: {memory_after - memory_before:.1f} MB")
    
    # Test procesare cu monitoring memorie
    test_chunks = [f"Test chunk {i} pentru monitoring memorie" for i in range(50)]
    
    memory_before_processing = process.memory_info().rss / 1024 / 1024
    embeddings = converter.generate_embeddings_streaming(test_chunks)
    memory_after_processing = process.memory_info().rss / 1024 / 1024
    
    print(f"ğŸ’¾ Memorie Ã®nainte de procesare: {memory_before_processing:.1f} MB")
    print(f"ğŸ’¾ Memorie dupÄƒ procesare: {memory_after_processing:.1f} MB")
    print(f"ğŸ“Š Memorie folositÄƒ pentru procesare: {memory_after_processing - memory_before_processing:.1f} MB")
    
    # Cleanup
    del embeddings
    gc.collect()
    
    memory_after_cleanup = process.memory_info().rss / 1024 / 1024
    print(f"ğŸ—‘ï¸ Memorie dupÄƒ cleanup: {memory_after_cleanup:.1f} MB")
    
    return True

def run_all_tests():
    """RuleazÄƒ toate testele de optimizare"""
    print("ğŸš€ TESTARE OPTIMIZÄ‚RI PDF TO EMBEDDINGS")
    print("=" * 60)
    
    tests = [
        ("InstrucÈ›iune de retrieval", test_retrieval_instruction),
        ("Normalizarea embeddings-urilor", test_normalization),
        ("Chunking avansat cu overlap", test_advanced_chunking),
        ("MetricÄƒ cosine ChromaDB", test_cosine_similarity),
        ("CÄƒutare cu scoruri globale", test_search_with_scores),
        ("ÃmbunÄƒtÄƒÈ›iri performanÈ›Äƒ", test_performance_improvements),
        ("Utilizarea memoriei", test_memory_usage),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, success))
            print(f"âœ… {test_name}: {'PASSED' if success else 'FAILED'}")
        except Exception as e:
            results.append((test_name, False))
            print(f"âŒ {test_name}: FAILED - {e}")
    
    # Sumar final
    print("\nğŸ¯ REZULTATE FINALE")
    print("=" * 60)
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "âœ… PASSED" if success else "âŒ FAILED"
        print(f"  {test_name}: {status}")
    
    print(f"\nğŸ“Š Scor final: {passed}/{total} teste trecute")
    print(f"ğŸ“ˆ Rata de succes: {passed/total*100:.1f}%")
    
    if passed == total:
        print("ğŸ‰ Toate optimizÄƒrile funcÈ›ioneazÄƒ corect!")
    else:
        print("âš ï¸ Unele optimizÄƒri necesitÄƒ atenÈ›ie!")
    
    return passed == total

if __name__ == "__main__":
    run_all_tests()